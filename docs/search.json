[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning diary",
    "section": "",
    "text": "Introduction\nHello! My name is Yihan Li and I’m from Chengdu, a city in Southwest China renowned for its pandas and hotpot. During my undergraduate studies in Urban Management at the University of Electronic Science and Technology of China, I developed a keen interest in courses like Data Mining, Principles and Applications of Artificial Intelligence, and GIS. This interest sparked my passion for applying these practical skills to solve real-world problems, even leading me to view smart cities as a promising direction for urban development. Fortuitously, I’m currently pursuing an MSc in Urban Spatial Science at CASA, which I was always dreamed of.\nAlthough I had some exposure to related courses previously, my knowledge was not in-depth. This master’s program represented an opportunity for me to enhance my skills in geospatial analysis and coding. This week marks potentially my last to take courses as a student, cause in the latter half of this year, I will embark on a job search. I’m deeply grateful for the invaluable experiences and skills I’ve gained here. I aspire to apply the knowledge acquired to the development of my hometown.\nThis website serves as a learning diary for my module, Remotely Sensing Cities and Environments, where I document my thoughts and learning journey. I have learned fundamentals about remote sensing, and also had a deeper understanding about some related applications and practicals. I hope that you enjoy it!"
  },
  {
    "objectID": "Week1.html#summary",
    "href": "Week1.html#summary",
    "title": "1  Week1 An Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 Mind Map\nThis is a hand-drawn mind map for Lecture 1, which I find exceptionally beneficial for summarizing topics. This week’s lecture introduced the fundamental aspects of remote sensing and its applications.\n\n\n\n\n\n\n\n\n\n\nFigure: Mind map for Lecture 1\n\n\n\n1.1.2 EMR interactions with the Earth’s atmosphere\nElectromagnetic radiation (EMR) interacting with the Earth’s atmosphere undergoes three main processes: refraction, scattering, and absorption.\n\n\n\n\n\n\n\n\n\n\nFigure: Interaction of EMR in the Atmosphere\n\n\nSource: (Pokhrel 2017)\n\nRefraction occurs as EMR transitions from the vacuum of outer space (with virtually zero density) into the denser atmosphere, causing the radiation to bend and slow due to the differing refractive indices of space and the atmosphere.\nScattering, the redirection of photon paths, occurs when photons interact with atmospheric components. Rayleigh scattering is due to interactions with particles much smaller than the wavelength of the radiation (e.g., N2, O2, CO2 gases), resulting in the blue sky. Mie scattering occurs with particles about the same size as the radiation wavelength (e.g., smoke, dust), and larger particles cause additional scattering types.\nAbsorption happens when atmospheric gases (primarily H2O, CO2, and O3) absorb photons, converting them into molecular vibrations. These are later re-emitted at longer wavelengths, often outside the optical remote sensing spectrum but relevant for thermal remote sensing. Absorption efficiency varies with the radiation’s wavelength, aligning with the absorbing gas’s resonant frequency, influenced by its molecular structure.\n\n\n1.1.3 EMR interactions with the Earth’s surface\nOnce EMR penetrates the atmosphere without being absorbed or scattered away, it interacts with the Earth’s surface. At this point, each photon either gets absorbed by the surface or reflected back towards space. The likelihood of reflection over absorption is determined by the surface’s reflectance, which varies with both the surface material and the radiation’s wavelength. Each type of surface material displays a unique spectral signature, defining the proportion of radiation it reflects across different wavelengths.\nSpectral signatures also facilitate geological surveying by identifying minerals with distinct reflectance patterns, indicating various sub-surface conditions. Finally, EMR reflected from the Earth’s surface must navigate back through the atmosphere, encountering refraction, scattering, and absorption once more before detection by space-based sensors. This complexity underlines the advantage of airborne sensors, which can measure reflected EMR without it having to traverse the atmosphere a second time, offering clearer data for analysis.\n\n\n\n\n\n\n\n\n\n\nFigure: Interaction of EMR with Earth’s surface.\n\n\nSource: (Pokhrel 2017)"
  },
  {
    "objectID": "Week1.html#applications",
    "href": "Week1.html#applications",
    "title": "1  Week1 An Introduction to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nRemote sensing plays a pivotal role in urban sustainability, especially in the geospatial assessment of renewable energy technologies such as wind, solar, wave, biomass, and geothermal energy. For instance, Gooding et al. utilized LiDAR digital surface models to estimate the physical and socio-economic potential of rooftop photovoltaic (PV) generation, while Sun et al. developed a regional model and its economic feasibility for solar PV potential using digital elevation models.\nIn terms of exploring the potential of geothermal resources, Van Der Meer et al. published a comprehensive review on the potential of remote sensing technologies(Meer et al. 2014). Ahamed et al. reviewed the application of remote sensing in assessing the biophysical characteristics of energy crops for managing biomass at specific sites. Rusu and Onea evaluated wind and wave energy resources along the Caspian Sea coast(Rusu and Onea 2013).\n\n\n\n\n\n\n\n\n\n\nFigure: Key urban sustainability applications of remote sensing\n\n\nSource: (Kadhim, Mourshed, and Bray 2016)"
  },
  {
    "objectID": "Week1.html#reflections",
    "href": "Week1.html#reflections",
    "title": "1  Week1 An Introduction to Remote Sensing",
    "section": "1.3 Reflections",
    "text": "1.3 Reflections\nReflecting on this week’s lessons, I’m struck by its vast potential,considering that I have never specially learned about remote sensing. The dive into how electromagnetic waves interact with the Earth’s surface and atmosphere opened my eyes to the complexities of remote sensing. Exploring the four resolutions of remote sensing data—spectral, spatial, temporal, and radiometric—highlighted the critical role of constraints, whether environmental or sensor-related, in shaping our data choices. This understanding challenges me to think critically about the data I use and its suitability for specific applications. The lesson reinforced the importance of considering these interactions and resolutions in my future work, inspiring me to explore innovative ways to overcome these constraints for more effective data utilization in environmental studies."
  },
  {
    "objectID": "Week1.html#references",
    "href": "Week1.html#references",
    "title": "1  Week1 An Introduction to Remote Sensing",
    "section": "1.4 References",
    "text": "1.4 References\n\n\n\n\nKadhim, Nada, Monjur Mourshed, and Michaela Bray. 2016. “Advances in Remote Sensing Applications for Urban Sustainability.” Euro-Mediterranean Journal for Environmental Integration 1 (1): 7.\n\n\nMeer, Freek van der, Christoph Hecker, Frank van Ruitenbeek, Harald van der Werff, Charlotte de Wijkerslooth, and Carolina Wechsler. 2014. “Geologic Remote Sensing for Geothermal Exploration: A Review.” International Journal of Applied Earth Observation and Geoinformation 33: 255–69.\n\n\nPokhrel, Samir. 2017. “Unit-2 Interaction of EMR with Earth and Atmosphere.” In. https://api.semanticscholar.org/CorpusID:202916529.\n\n\nRusu, Eugen, and Florin Onea. 2013. “Evaluation of the Wind and Wave Energy Along the Caspian Sea.” Energy 50: 1–14."
  },
  {
    "objectID": "Week2.html",
    "href": "Week2.html",
    "title": "2  Week2 Xaringan",
    "section": "",
    "text": "Here is a short presentation introducing the Sentinel-2 mission。"
  },
  {
    "objectID": "Week3.html#summary",
    "href": "Week3.html#summary",
    "title": "3  Week3 Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Mind Map\nThe summary of this week’s content is outlined below in the mind map.\n\n\n\n\n\n\n\n\n\n\nFigure: Mind map for Lecture 3\n\nAnd I also want to add more detailed information about the enhancement techniques for remote sensing, cause I was quite confused when first exposed to this knowledge.\n\n\n3.1.2 NDVI\nNormalized Difference Vegetation Index (NDVI) is a standardized index that allows quantifying vegetation by measuring the difference between near-infrared and red light. NDVI values range from -1 to 1, with higher values indicating greater levels of vegetation health and vigor. This index is extensively used in agriculture for crop monitoring, environmental conservation efforts, and assessing vegetation health on a global scale.\n\n\n3.1.3 Texture\nTexture analysis involves the examination of the physical surface properties and patterns within an image. By analyzing the spatial distribution of intensity or color variations, texture analysis can identify different land cover types, geological formations, or urban structures. This technique enhances the interpretation of imagery by providing insights into the surface structure and composition that are not readily apparent in raw spectral data.\n\n\n3.1.4 PCA\nPrincipal Component Analysis (PCA) is a statistical procedure that transforms a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. In the context of remote sensing, PCA is used to reduce the dimensionality of multispectral or hyperspectral data while retaining most of the variation present in the original dataset. This reduction helps in highlighting the most significant features in the imagery, facilitating better classification, and reducing computational complexity."
  },
  {
    "objectID": "Week3.html#applications",
    "href": "Week3.html#applications",
    "title": "3  Week3 Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nIn this study(Wu, Jin, and Fan 2016), the authors study the performance of seven topographic correction methods across complex terrains using multi-source DEMs and Landsat-8 OLI data. It brings to light the crucial interplay between the choice of Digital Elevation Models (DEMs) and the efficacy of various topographic correction approaches, particularly emphasizing the superiority of the SCS+C correction method in various contexts. The findings intriguingly suggest that freely available, open-access DEMs can often outperform local topographic maps in topographic correction applications. This revelation not only marks a shift towards utilizing global DEM resources but also highlights the potential for enhancing environmental monitoring capabilities, especially in underdeveloped regions lacking access to high-quality local DEMs.\n\n\n\n\n\n\n\n\n\n\nFigure: Location of the study area (a) and the false colour composition of the Landsat-8 OLI image of the study area (b), overlaid on hillshade map based on the local DEM. The red dash-line rectangle outlines the location of Landsat image subset.\n\n\nSource: (Wu, Jin, and Fan 2016)"
  },
  {
    "objectID": "Week3.html#reflections",
    "href": "Week3.html#reflections",
    "title": "3  Week3 Corrections",
    "section": "3.3 Reflections",
    "text": "3.3 Reflections\nThis week’s lecture covered many methodologies and Professional vocabulary. It was a steep learning curve. This process of re-organizing my own mind-map, albeit time-consuming, has enriched my understanding of correcting data before analysis. Raw remote sensing data, while rich in information, often contain distortions caused by the atmosphere, sensor biases, or topographical effects. Without appropriate corrections, these distortions can lead to inaccuracies in interpreting the data, which could have significant implications for research findings and real-world applications."
  },
  {
    "objectID": "Week3.html#references",
    "href": "Week3.html#references",
    "title": "3  Week3 Corrections",
    "section": "3.4 References",
    "text": "3.4 References\n\n\n\n\nWu, Qiong, Yuan Jin, and Hui Fan. 2016. “Evaluating and Comparing Performances of Topographic Correction Methods Based on Multi-Source DEMs and Landsat-8 OLI Data.” International Journal of Remote Sensing 37 (19): 4712–30."
  },
  {
    "objectID": "Week6.html#summary",
    "href": "Week6.html#summary",
    "title": "5  Week6 Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Mind Map\nThis is this week’s mind map. This week introduced us Google Earth Engine.\n\n\n\n\n\n\n\n\n\n\nFigure: Mind map for Lecture 6\n\n\n\n5.1.2 Practical"
  },
  {
    "objectID": "Week9.html#summary",
    "href": "Week9.html#summary",
    "title": "8  Week9 SAR in GEE",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Mind Map\nThis is the mind map for Lecture 9. This week’s lecture introduced the fundamental aspects of SAR and its applications.\n\n\n\n\n\n\n\n\n\n\nFigure: Mind map for Lecture 9\n\n\n\n8.1.2 SAR\nIn order to get more familiar with SAR, I will cover the main related concepts.\nSAR (Synthetic Aperture Radar) operates as an active sensor system, which means it emits its own energy to illuminate targets and measures the energy that is reflected back. This capability allows SAR to penetrate through cloud cover, making it a powerful tool for Earth observation regardless of weather conditions or time of day.\nInSAR (Interferometric SAR) is an advanced application of SAR technology, which involves using two or more SAR images to create maps of surface deformation or digital elevation models (DEMs). It calculates the phase difference between the SAR images taken at different times to measure the relative height of the Earth’s surface with high precision.\nDInSAR (Differential InSAR) takes this a step further by analyzing the phase difference between pairs of images acquired over the same area at different times to detect and measure the subtle changes in the Earth’s surface, such as uplift or subsidence. By comparing these phase differences and removing the effects of overall topography using a DEM, DInSAR can reveal land movements caused by factors like earthquakes, volcanic activity, or groundwater extraction, with millimeter-level accuracy. This technique is particularly valuable for monitoring and studying geophysical phenomena, contributing to our understanding of natural hazards and the dynamics of the Earth’s crust."
  },
  {
    "objectID": "Week6.html#applications",
    "href": "Week6.html#applications",
    "title": "5  Week6 Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nIn a study conducted by Lalit Kumar and Onisimo Mutanga, a comprehensive analysis of 300 research papers published in journals from January 2010 to June 2017 was carried out to understand the applications of Google Earth Engine (GEE) across various disciplines(Kumar and Mutanga 2018).\nThe findings revealed that the majority of global studies and publications targeted land cover and vegetation. Forest and vegetation studies topped the list, constituting 17% of the total, followed by land use and land cover research at 10%. Ecosystem and sustainability, wetland and hydrology, and data manipulation each accounted for 8% of the studies. Agriculture came in next at 7%, mapping and change detection at 5%, and both remote sensing applications and modelling and geoscience research were at 4%. Cloud computing, soil, disease, climate science, and urban studies each made up 3% of the research, while natural hazard and disaster studies were at 2%. The “others” category, comprising 11% of the applications, included diverse areas such as economics, air pollution, virtual environments, air temperature, and archaeology, indicating a wide but less explored variety of applications beyond the dominant focus on natural resources mapping and management.\n\n\n\n\n\n\n\n\n\n\nFigure: A broad categorization of application disciplines of GEE across the 300 papers surveyed.\n\n\nSource: (Kumar and Mutanga 2018)\n\nThis analysis underscores a significant emphasis on vegetation and forest monitoring, as well as land cover/use change mapping within the GEE research community. It also highlights the relative scarcity of studies focusing on disaster monitoring, disease, and soil, despite potential overlaps between vegetation/agricultural diseases and the broader categories of vegetation and crop disease research."
  },
  {
    "objectID": "Week6.html#references",
    "href": "Week6.html#references",
    "title": "5  Week6 Google Earth Engine",
    "section": "5.4 References",
    "text": "5.4 References\n\n\n\n\nKumar, Lalit, and Onisimo Mutanga. 2018. “Google Earth Engine Applications Since Inception: Usage, Trends, and Potential.” Remote Sensing 10 (10): 1509."
  },
  {
    "objectID": "Week6.html#reflections",
    "href": "Week6.html#reflections",
    "title": "5  Week6 Google Earth Engine",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nGoogle Earth Engine stands out as a remarkably powerful tool for data analysis, showcasing the strides made in technology and data analytics. Its capacity to process and analyze massive datasets swiftly contrasts sharply with the longer processing times in software like SNAP and R for considerably smaller data volumes. This efficiency is particularly valuable in environmental studies and related fields, where timely data analysis is crucial. It opens up a new avenue for learning and applying a language that is versatile and widely used beyond traditional web development. However, it’s worth noting that utilizing GEE effectively does require a foundation in coding, which might limit its accessibility to a broader audience."
  },
  {
    "objectID": "Week7.html#summary",
    "href": "Week7.html#summary",
    "title": "6  Week7 Classification",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Mind Map\nThis is the mind map for Lecture 7. This week’s lecture introduced how classied data is used and how to classify.\n\n\n\n\n\n\n\n\n\n\nFigure: Mind map for Lecture 7"
  },
  {
    "objectID": "Week7.html#applications",
    "href": "Week7.html#applications",
    "title": "6  Week7 Classification",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nSVM and ML classifiers have been extensively utilized for their robustness in various contexts. ML, often paired with supervised classification methods, has been applied in urban land cover and development mapping, achieving up to 84.4% overall accuracy in some studies (Thapa and Murayama 2009). On the other hand, SVM, a set of related learning algorithms, has demonstrated overall accuracies surpassing 86.6% (TAATI et al. 2015) showcasing its superiority in producing high-quality results.\nAccuracy assessment is a complex yet crucial step in land cover classification and mapping, involving the analysis of a map or classification’s correctness (Foody 2002). It includes measuring map quality, evaluating classification algorithms, and identifying errors. Our research suggests SVM as a preferable choice for precise land cover classification, especially in urban and built-up areas, due to its higher user and producer accuracy compared to ML. This recommendation is based on its effectiveness in distinguishing urban/built-up land cover, attributed to the more distinct features identified by SVM.\nIn the study by Rimal,Rijal and Kunwar, they focused on comparing the effectiveness of two widely used classification algorithms: Support Vector Machine (SVM) and Maximum Likelihood (ML), for land cover classification in the Kathmandu Valley of Nepal from 1988 to 2016. The research found that the User’s and Producer’s Accuracy of SVM classifier were both relatively higher than the ML classifier. And SVM classifier identified all the classes more accurately than the ML classifier(Rimal, Rijal, and Kunwar 2020).\n\n\n\n\n\n\n\n\n\n\nFigure: Overall classification accuracy of SVM and ML in different classification years\n\n\nSource: (Rimal, Rijal, and Kunwar 2020)"
  },
  {
    "objectID": "Week7.html#references",
    "href": "Week7.html#references",
    "title": "6  Week7 Classification",
    "section": "6.4 References",
    "text": "6.4 References\n\n\n\n\nFoody, Giles M. 2002. “Status of Land Cover Classification Accuracy Assessment.” Remote Sensing of Environment 80 (1): 185–201.\n\n\nRimal, Bhagawat, Sushila Rijal, and Ripu Kunwar. 2020. “Comparing Support Vector Machines and Maximum Likelihood Classifiers for Mapping of Urbanization.” Journal of the Indian Society of Remote Sensing 48 (1): 71–79.\n\n\nTAATI, Abbas, Fereydoon SARMADIAN, Amin MOUSAVI, Chamran Taghati Hossien POUR, and Amir Hossein Esmaile SHAHIR. 2015. “Land Use Classification Using Support Vector Machine and Maximum Likelihood Algorithms by Landsat 5 TM Images.” Walailak Journal of Science and Technology (WJST) 12 (8): 681–87.\n\n\nThapa, Rajesh Bahadur, and Yuji Murayama. 2009. “Examining Spatiotemporal Urbanization Patterns in Kathmandu Valley, Nepal: Remote Sensing and Spatial Metrics Approaches.” Remote Sensing 1 (3): 534–56."
  },
  {
    "objectID": "Week7.html#reflections",
    "href": "Week7.html#reflections",
    "title": "6  Week7 Classification",
    "section": "6.3 Reflections",
    "text": "6.3 Reflections\nThis week’s exploration into the image classification has been a blend of absorbing theory and practical learning. I’m intrigued by the concept of Gini impurity used in Classification and Regression Trees (CART), a straightforward yet powerful measure for decision-making in tree algorithms. Another highlight was grappling with the challenge of overfitting—a reminder that more complex models aren’t always better, especially when they might not generalize well to new data.\nActually I am also studying these concepts in the module of CASA0006. I consider it’s very useful and interesting to see how these methods are used in remote sensing.\nAs a graduate student, these insights are more than academic concepts; they’re tools that can be wielded to uncover patterns in environmental data that are otherwise invisible. This knowledge empowers us to make informed decisions, whether it’s in managing natural resources or planning urban expansions."
  },
  {
    "objectID": "Week8.html#summary",
    "href": "Week8.html#summary",
    "title": "7  Week8 Classification2",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Mind Map\nThis is the mind map for Lecture 8. This week’s lecture introduced advanced techniques in remote sensing for land cover classification.\n\n\n\n\n\n\n\n\n\n\nFigure: Mind map for Lecture 8\n\n\n\n7.1.2 Tools for managing spatial autocorrelation\nI would like to add more information about spatial autocorrelation, cause When training and testing classification models in remote sensing, it is crucial to consider spatial autocorrelation.\nSpatial autocorrelation refers to the principle that spatial data points close to each other are more likely to have similar values than those that are further apart. Ignoring spatial autocorrelation can lead to overly optimistic accuracy assessments and model overfitting.\nObject-Based Image Analysis (OBIA) can help address spatial autocorrelation because it groups nearby pixels into objects or segments based on their spectral and spatial properties. This method recognizes that adjacent pixels are likely to be more related and thus analyzes the image at the object level rather than at the individual pixel level. By doing so, it inherently accounts for the spatial context and can reduce the bias in accuracy assessment caused by spatial autocorrelation.\nSpatial cross-validation is specifically designed to handle spatial autocorrelation when assessing model performance. Unlike traditional cross-validation, which randomly splits the dataset into training and testing sets, spatial cross-validation ensures that spatially autocorrelated observations are not split across training and testing sets. It partitions the data based on spatial location, typically ensuring that the folds are spatially disjoint. This means that each fold acts as a truly independent sample of the data, providing a more reliable estimate of the model’s performance on unseen data.\nIn summary, both OBIA and spatial cross-validation are useful approaches for managing spatial autocorrelation, leading to more robust and reliable classification models in remote sensing."
  },
  {
    "objectID": "Week8.html#applications",
    "href": "Week8.html#applications",
    "title": "7  Week8 Classification2",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nIn the respective studies on the spatial distribution of COVID-19, both (Kang et al. 2020) and (Mollalo, Vahedi, and Rivera 2020) shed light on the significance of spatial autocorrelation in epidemiological research.\nKang et al. applied Moran’s I statistic to determine the spatial clustering of COVID-19 cases in China, adjusting for skewness in the data by employing log transformation. This method revealed significant spatial dependencies, with different models capturing the extent of disease spread based on geographic proximity, population density, and healthcare resources. Notably, their study suggested that areas geographically closer to Wuhan showed early signs of COVID-19 clusters before travel restrictions were implemented.\n\n\n\n\n\n\n\n\n\n\nFigure: Plots of Moran’s I statistic and p-values\n\n\nSource: (Kang et al. 2020)\n\nConversely, Mollalo et al. delved into the spatial variability of COVID-19 incidence across the United States using a geodatabase of various factors. Their method employed spatial lag and spatial error models, as well as geographically weighted regression (GWR) and multiscale GWR (MGWR), to account for spatial non-stationarity. MGWR, in particular, demonstrated higher explanatory power for disease variability, indicating a strong spatial relationship influenced by factors such as income inequality and healthcare provision.\n\n\n\n\n\n\n\n\n\n\nFigure: Geographic distribution of local R2 of GWR and MGWR models for COVID-19 incidence rate associated with income inequality, median household income, % of nurse practitioners, and % of black females across the continental United States.\n\n\nSource: (Mollalo, Vahedi, and Rivera 2020)\n\nBoth studies underscore the importance of considering spatial autocorrelation to understand the spread of COVID-19. The Chinese study primarily utilized proximity and direct relationships in defining spatial adjacency, whereas the U.S. study integrated a broader spectrum of socioeconomic and environmental variables, showcasing the disease’s complexity and the multifaceted nature of its spread. These approaches highlight the necessity of incorporating spatial dynamics into epidemiological models to accurately capture the influence of various factors on disease transmission."
  },
  {
    "objectID": "Week8.html#reflections",
    "href": "Week8.html#reflections",
    "title": "7  Week8 Classification2",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nIn comparison to last week, this week’s lecture has provided a more profound insight into how to effectively model and interpret environmental data.\nIt has introduced us the concept of accuracy assessment, which has profoundly enhanced my understanding of it, especially following up on last week’s comparative study of SVM and ML classifiers by doing the accuracy assessment. I’m really excited. It allowed me to revisit last week’s literature with a deeper perspective, understanding not just the ‘what’ but the ‘why’ behind the performance metrics.\nFurthermore, while I was introduced to the concept of spatial autocorrelation in my CASA0005 course, this module has deepened my comprehension of its significance in the realm of geographical data. Recognizing the interdependence of spatial data points is crucial for the credibility of classification processes in remote sensing. Overlooking the spatial linkages could skew the results, which underlines the fact that our data is not just a collection of isolated points but a mirror of the interconnected world we inhabit. It serves as a powerful reminder that, in working with this data, we must always account for the intricate web of relationships that define the environment around us."
  },
  {
    "objectID": "Week8.html#references",
    "href": "Week8.html#references",
    "title": "7  Week8 Classification2",
    "section": "7.4 References",
    "text": "7.4 References\n\n\n\n\nKang, Dayun, Hyunho Choi, Jong-Hun Kim, and Jungsoon Choi. 2020. “Spatial Epidemic Dynamics of the COVID-19 Outbreak in China.” International Journal of Infectious Diseases 94: 96–102.\n\n\nMollalo, Abolfazl, Behzad Vahedi, and Kiara M Rivera. 2020. “GIS-Based Spatial Modeling of COVID-19 Incidence Rate in the Continental United States.” Science of the Total Environment 728: 138884."
  },
  {
    "objectID": "Week9.html#applications",
    "href": "Week9.html#applications",
    "title": "8  Week9 SAR in GEE",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nThe application of deep learning techniques to SAR imagery analysis covers areas such as object detection, classification, tracking, intelligent processing, and interferometric SAR technology(T. Zhang, Zeng, and Zhang 2023).\nIn the study written by Tan et al.,a feature-preserving heterogenous remote sensing image transformationthe model represents a significant stride in enhancing optical image details while reducing spectral distortion. This model’s ability to enhance feature reconstruction and its efficiency in parameter economy, as validated by Sentinel-2 satellite imagery, marks a notable advancement in the field(Tan et al. 2021).\n\n\n\n\n\n\n\n\n\n\nFigure: (a) Overview of the method: the SAR image affected by speckling is the input, and the Despeckling GAN generates a corresponding optical grayscale image as output. The optical grayscale image is then sent as input to the second generator network Colorization GAN, and the output is an optical color image. (b) Examples of generating optical grayscale images and optical color images through the Serial GANs.\n\n\nSource: (Tan et al. 2021)\n\nZhang et al.’s work on a self-supervised despeckling algorithm, SSEUNet, brings innovation by generating noisy-noisy image pairs from real-world SAR images, which enables the training of deep convolutional neural networks on authentic SAR data. This approach, coupled with an enhanced U-Net, showcases substantial improvements in speckle noise reduction while preserving image features, setting new standards in state-of-the-art despeckling methods(G. Zhang et al. 2021).\n\n\n\n\n\n\n\n\n\n\nFigure: The despeckled visual results of a simulated SAR image\n\n\nSource: (G. Zhang et al. 2021)\n\nBoth studies underscore the potential of deep learning to revolutionize SAR image processing, offering a paradigm shift from traditional methods to more sophisticated, feature-focused approaches. While Tan et al.’s study provides a new model for heterogenous transformation, Zhang et al. suggest practical improvements in despeckling, acknowledging that further advancements in network speed and data augmentation effects on SAR imagery are areas ripe for future exploration. Together, these works not only push the boundaries of SAR image analysis but also pave the way for comprehensive, efficient, and precise remote sensing applications."
  },
  {
    "objectID": "Week9.html#reflections",
    "href": "Week9.html#reflections",
    "title": "8  Week9 SAR in GEE",
    "section": "8.3 Reflections",
    "text": "8.3 Reflections\nThis week, I get to know more about the complexity and charm of SAR data.\nI consider the concept of polarization in remote sensing is similar to that of polarized lenses used in our everyday life to some extent. In both cases, the polarization helps to filter and clarify the reflected signals we perceive. In remote sensing, polarization filters Earth’s reflections in varied ways, offering us valuable clues about the surface. It’s intriguing to consider how different materials reflect these waves; rough surfaces or vegetation, for example, have distinct interactions with different polarizations. This not only enhances the quality of the images but also improves our ability to distinguish and analyze various surface features for environmental monitoring and other applications.\nWhile SAR’s utility in remote sensing is undeniable, particularly for its cloud-penetrating capabilities ensuring consistent data acquisition, it’s not without its challenges. The preprocessing required for SAR data, including steps like orbit file application, radiometric calibration, and speckle filtering, can be quite involved. Despite these complexities, SAR’s potential in remote sensing continues to grow, making it crucial to master its use for advancing geospatial analysis."
  },
  {
    "objectID": "Week9.html#references",
    "href": "Week9.html#references",
    "title": "8  Week9 SAR in GEE",
    "section": "8.4 References",
    "text": "8.4 References\n\n\n\n\nTan, Daning, Yu Liu, Gang Li, Libo Yao, Shun Sun, and You He. 2021. “Serial GANs: A Feature-Preserving Heterogeneous Remote Sensing Image Transformation Model.” Remote Sensing 13 (19): 3968.\n\n\nZhang, Gang, Zhi Li, Xuewei Li, and Sitong Liu. 2021. “Self-Supervised Despeckling Algorithm with an Enhanced u-Net for Synthetic Aperture Radar Images.” Remote Sensing 13 (21): 4383.\n\n\nZhang, Tianwen, Tianjiao Zeng, and Xiaoling Zhang. 2023. “Synthetic Aperture Radar (SAR) Meets Deep Learning.” Remote Sensing. MDPI."
  },
  {
    "objectID": "Week4.html#summary",
    "href": "Week4.html#summary",
    "title": "4  Week4 Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nFor this week’s practical, I chose New York City as my focus area, particularly examining its resilience planning within the OneNYC 2050 initiative.\nA growing population, aging infrastructure, a changing climate, and an evolving economy posed challenges to the city’s success and quality of life. New York City Municipality recognized that they will determine the city’s own future by how the citizens as well as local authorities respond to and shape these changes with their own actions. Since the first PlaNYC in 2007, the City has made considerable progress on reaching its goals(SISI, n.d.).\n\n\n\n\n\n\n\n\n\n\nFigure: Plans about PlaNYC\n\nBut OneNYC 2050,a more comprehensive strategy, aims to address the multifaceted challenges posed by climate change, including urban flooding, heatwaves, and rising sea levels. As NYC navigates through these environmental hurdles, the necessity for sustainable urban growth and resilience becomes increasingly apparent.\nOneNYC 2050 not only sets ambitious goals for a sustainable city but also outlines actionable steps towards achieving them, focusing on enhancing ecosystem services, promoting biodiversity, and improving coastal flood resilience.\n\n\n\n\n\n\n\n\n\n\nFigure: OneNYC 2050\n\nNew York City’s approach is reflective of broader issues faced by urban centers worldwide, especially those in vulnerable coastal regions. The policy’s emphasis on integrating socio-ecological systems and biodiversity into urban planning mirrors global efforts to create resilient, sustainable cities in the face of climate change(Caputo et al. 2016)."
  },
  {
    "objectID": "Week4.html#applications",
    "href": "Week4.html#applications",
    "title": "4  Week4 Policy",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nRemotely sensed data is pivotal in supporting NYC’s resilience planning goals. Satellite imagery and data, such as those provided by Landsat or Sentinel-2, can be instrumental in monitoring urban heat islands, assessing green infrastructure effectiveness, and tracking changes in coastal zones. These datasets offer critical insights into the city’s evolving landscape, allowing for targeted interventions in areas most at risk of flooding or heat stress.\nFor example, high-resolution imagery can identify areas where green roofs or urban parks might be most effective in mitigating heat, while elevation and radar data can help model flood risk areas, guiding the development of resilient infrastructure. By leveraging these remotely sensed datasets, NYC can enhance its urban planning processes, making informed decisions that align with its sustainability and resilience objectives."
  },
  {
    "objectID": "Week4.html#reflections",
    "href": "Week4.html#reflections",
    "title": "4  Week4 Policy",
    "section": "4.3 Reflections",
    "text": "4.3 Reflections\nEngaging with New York City’s OneNYC 2050 initiative and the role of remotely sensed data in urban resilience planning has been enlightening. It has reinforced the complexity of addressing urban sustainability and resilience, showcasing the interconnected nature of climate change impacts, urban development, and environmental management. The use of remote sensing data in this context highlights a forward-thinking approach to urban planning, where data-driven strategies can lead to more effective and adaptive solutions.\nThis research has also highlighted the critical link between local actions and global sustainability goals, such as the Sustainable Development Goals (SDGs), demonstrating how cities like New York can lead by example in tackling climate change. It underscores the importance of innovative tools like remote sensing in crafting policies that not only respond to current challenges but also anticipate future needs.\nReflecting on the OneNYC 2050 strategy and its applications, it’s clear that incorporating advanced technology and data analysis into urban planning is no longer optional but a necessity. As cities continue to grow and face unprecedented challenges, the lessons learned from New York’s approach to resilience planning will undoubtedly serve as valuable blueprints for other urban areas globally."
  },
  {
    "objectID": "Week4.html#references",
    "href": "Week4.html#references",
    "title": "4  Week4 Policy",
    "section": "4.4 References",
    "text": "4.4 References\n\n\n\n\nCaputo, Samantha, Annalise Kukor, Nathaniel Lapides, and Alex Sturtevant. 2016. “A Critical Analysis of Well-Being, Consumption and Growth Within New York City’s OneNYC Plan for a Strong and Just City.” MASTER’S PORTFOLIO, 48.\n\n\nSISI, LIANG. n.d. “From Green to Resiliency: A Review of Evolution, Experiences and Implementations of American Climate Change Action Plan.”"
  }
]